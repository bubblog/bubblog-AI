# 하이브리드 서치 고도화 기록: 개념, 설계, 그리고 문제 해결기

블로그 문서 검색 품질을 한 단계 끌어올리기 위해 “하이브리드 서치(벡터 + 텍스트)”를 도입하고, 왜 ANN(근사 최근접 탐색)이 아니라 KNN(정확 최근접 탐색)에 가까운 방식으로 구현했는지, 마주친 문제들을 어떤 기술로 해결했는지까지 담았다.

## 용어 정리: Pre-filter / Post-filter · KNN / ANN

- Pre-filter: 검색 전에 후보 풀을 “조건(예: user_id, category, 기간)”으로 미리 줄여서, 줄어든 부분 집합에서 검색/순위를 수행하는 방식. 인덱스가 전체 데이터 기준으로 구성되어 있으면, 선택률이 낮아질수록(부분 집합이 작아질수록) 전역 인덱스의 성능·품질 이점이 약해질 수 있다.
- Post-filter: 먼저 전역에서 넓게 후보를 뽑은 뒤(예: ANN), 그 결과에 조건을 적용해 뒤늦게(사후) 거르는 방식. 리콜은 높지만, 필터로 많이 떨어져나가면 최종 히트 수가 불안정할 수 있어, 초기 후보 폭(top_k×factor)을 충분히 잡는 게 중요하다.
- KNN(정확 최근접): 근사 없이 정확한 거리 기반으로 최근접을 계산. 일관된 품질과 필터 친화성이 장점이지만, 전역 대규모 탐색에서는 지연이 커질 수 있다.
- ANN(근사 최근접): 근사 인덱스(HNSW 등)로 전역 대규모 공간에서 빠르게 후보를 찾는다. 전역 탐색에서 매우 유리하지만, 강한 pre-filter와 결합하면 전역 인덱스의 최적화 구조가 깨져 이점이 약화될 수 있다.

## 하이브리드 서치의 기본 개념

하이브리드 서치는 두 가지 모달리티를 결합한다.
- 벡터 검색: 임베딩 간 코사인 유사도로 의미 기반 후보를 찾는다.
- 텍스트 검색: 키워드·질문과의 텍스트 유사도(문자열 유사도, 부분 일치)를 통해 정확 매칭을 잡아낸다.

두 경로의 장단점은 상호 보완적이다. 벡터는 개념/의도를 잘 잡지만 정확한 숫자·버전·고유 키워드엔 약하다. 반대로 텍스트는 정밀하지만 표현이 달라지면 놓친다. 우리는 LLM이 생성한 질문 재작성(rewrites)과 키워드(keywords)를 활용해 두 경로 모두의 리콜을 끌어올린 뒤, min–max 정규화와 가중합으로 점수를 융합한다.

## 왜 ANN 대신 KNN에 가까운 접근을 선택했는가

우리 검색은 “서버사이드 pre-filter(사전 필터)”를 적극적으로 사용한다. 즉, **유저**필터를 고정적으로 적용하고 카테고리/기간 필터를 먼저 적용해 사용자의 개인 코퍼스 안에서만 후보를 좁힌다. 이 구조에서는 전형적 ANN(HNSW 등)의 장점이 약화된다.

추가로, pre-filter 선택률이 10% 이하로 낮아지는 경우(예: user_id로 코퍼스를 강하게 좁힐 때 이를 **선택률**이라고 한다 즉, 선택률 <= 10%>), 전역 코퍼스에 맞춰 구축한 HNSW 인덱스의 “근사 탐색 경로”가 필터된 부분 집합에 대한 인덱스가 생성되어 있지 않으므로 ANN의 단점인 recall 하락(즉, 유사도가 높은 데이터를 놓치거나) 무엇보다 장점인 속도마저도 크게 줄어든다. 
쉽게 말해, 전체 데이터에 최적화된 그래프 위에서 극히 일부만 쓰려 하니, 전역 최적화 구조가 부분 집합 검색에는 잘 작동하지 않는 것이다. 그래서 사용자 스코프(ask)에서는 pre-filter 후 KNN(정확 계산)으로 품질과 일관성을 확보했다.

따라서 인덱스 레벨에서는 pgvector(HNSW)를 깔아두되, 실제 질의는 카테고리/기간으로 후보 집합을 줄인 뒤 “부분 집합 위 KNN에 가까운 정확 계산”으로 점수를 결합하는 전략을 택했다. 이렇게 하면 필터링-친화적이며 결과 일관성이 높다. 비용 대비 품질이 더 안정적이기도 하다.

- 결합 스코어: 우리는 청크 임베딩과 제목 임베딩의 가중 합, 그리고 텍스트 유사도를 뒤섞어 최종 점수를 만든다. 단일 벡터 순위 최적화만으로는 원하는 최종 순위를 바로 얻기 어렵다.

## 전체 파이프라인 설계

1) 검색 계획(Planner)
- 입력 질문을 바탕으로 LLM이 검색 계획 JSON을 생성한다. 특히 시간 필터는 “라벨(예: last_30_days)”로만 출력하고, 서버가 이를 절대 범위(from/to)로 정규화한다.
- 키워드 제약: 공백 없는 단일 토큰만 허용하고 1~5개로 캡(cap). 불용어/중복/특수문자는 정규화 단계에서 제거한다.
- 하이브리드 라벨(retrieval_bias) → alpha 매핑: lexical=0.30, balanced=0.50, semantic=0.75를 기본으로 사용한다.
- 재작성 단계화: `rewrite_1`은 보수적(paraphrase), `rewrite_2`는 동의어/엔티티 정규화를 포함, `rewrite_3+`는 의미 드리프트를 의도적으로 높여 표현을 확장한다. 모든 재작성은 질문형이 아닌 “서술형”으로 작성한다. 특히 개념/요약/의도 중심 질의(semantic bias)에서는 보다 공격적인 서술형 재작성으로 프레이징 커버리지를 넓힌다. 단, 사용자 코퍼스의 범위를 벗어나거나 시간 표현을 끼워 넣지 않는다.
 - 질문→서술 전환(Interrogative→Declarative): “~가 뭐야/무엇인가/알려줘” 같은 의문형 질문은, 모든 재작성을 “찾고 싶은 내용을 서술하는 문장”으로 바꾼다. 예) “S3가 뭐야?” → “Amazon S3는 AWS의 객체 스토리지 서비스다”. 시멘틱 유사도는 문맥/지식 서술과의 거리가 더 잘 측정되므로, 질의의 목적을 서술형으로 명시하면 벡터 검색 적합도가 높아진다. 이 제약은 프롬프트에서 강하게 유도하고, 서버 정규화는 보수적으로 유지한다(필요 최소한 외에는 재작성 텍스트를 서버에서 걸러내지 않음).

 예시(JSON: Planner 출력) S3가 뭐야?
 ```json
 {
   "mode": "rag",
   "top_k": 5,
   "threshold": 0.2,
   "weights": { "chunk": 0.7, "title": 0.3 },
   "rewrites": [
     "Amazon S3 개요",
     "Amazon S3는 AWS의 객체 스토리지 서비스다",
     "AWS 오브젝트 스토리지 S3"
   ],
   "keywords": ["S3", "AWS", "스토리지"],
   "hybrid": { "enabled": true, "retrieval_bias": "semantic", "max_rewrites": 3, "max_keywords": 5 },
   "filters": { "time": { "type": "label", "label": "last_30_days" } },
   "sort": "created_at_desc",
   "limit": 5
 }
 ```
 (서버는 `filters.time.label`을 절대 범위 `from/to`로 정규화해 저장소 레이어에 적용한다.)

### 질문에서 서술로의 전환이 왜 유효한가?

시멘틱 유사도는 보통 “질문” 자체보다 “지식/내용을 서술한 문장”과 더 잘 정렬된다. “~가 뭐야?” 같은 의문형은 질의 의도를 담고 있지만, 문서의 본문은 대개 “무엇이다/어떻게 한다”와 같이 서술형으로 쓰인다. 따라서 질의를 서술형으로 재구성하면 임베딩 공간에서 목표 컨텐츠와의 거리가 줄어들어 벡터 검색 리콜과 정밀도가 함께 좋아진다. 우리는 재작성 단계에 이 원칙을 반영해, 최소 하나의 재작성을 서술형으로 생성하도록 가이드를 강화했다.

2) 후보 수집(Retrieval)
- 벡터 경로: [원 질문 + 재작성] 각각 임베딩을 생성해 코사인 유사도 기반 후보를 모은다. 원 질문 대비 재작성 유사도를 측정해 유사도가 낮은 재작성은 벡터 경로에서 제외하고, 남은 재작성에는 [0.6, 1.2] 가중치를 곱해 영향력을 조절한다.
- 텍스트 경로: 질문 + 유지된 재작성 각각을 질의로 삼아 문자열 유사도(similarity)와 키워드 ILIKE ANY 매칭으로 후보를 모은다.
- Dedup 키: `${postId}:${chunkIndex}`로 통일해 문자열 청크 키의 불안정성을 제거했다.
 - 서술형 재작성 가중치 하한: 의문형을 서술형으로 바꾼 재작성은 임베딩 유사도가 약간 낮아질 수 있다. 이를 보상하기 위해 소폭의 가중치 하한을 둔다(semantic 바이어스에서는 최소 1.0, 그 외 0.95). 이렇게 하면 “지식 서술과의 정렬” 이점은 살리고, 과도한 가중 상향은 피한다.

3) 점수 융합(Ranking & Fusion)
- 모달리티별 점수를 min–max 정규화한다.
- bias 프리셋 기반 **임계치 부스팅**: 정규화된 점수가 임계치(sem/lex threshold)를 넘으면 +0.1 보너스를 주고 1.0에서 캡(cap)한다.
- 최종 점수: `score = alpha * vector + (1 - alpha) * text`로 결합한다.
- 포스트 다양성: 포스트당 청크 최대 2개로 제한해 한 포스트가 상위를 독식하지 않게 한다.
- 최종 limit: 계획의 `limit`을 최종 단계에서 적용한다.

4) 표면화(Outputs)
- SSE(v2): 기존 `hybrid_result`/`search_result`를 유지하면서 선택적 메타 이벤트(`hybrid_result_meta`, `search_result_meta`)로 스니펫/점수/청크 인덱스를 제공한다.

- REST(JSON): `GET /search/hybrid`는 글로벌 검색(전체 DB)을 수행한다. 시멘틱 경로는 ANN(HNSW)로 전역 후보를 먼저 모으고, 이후 텍스트/재작성/임계치 부스팅을 결합해 리랭크한다. 결과는 포스트 단위로 집계해 페이지네이션과 함께 반환한다.

## 현장에서 마주친 문제들과 해결

문제 1) 필터링 누락과 limit 미적용
- 증상: 카테고리/시간 필터가 계획/서비스 사이에서 헷갈려 제대로 반영되지 않거나, 최종 `limit`이 무시되는 케이스가 있었다.
- 해결: 필터는 서버가 단일 출처에서 주입(카테고리/유저)하고, 시간은 계획의 라벨을 서버가 절대 범위로 정규화하는 일관된 규칙을 확립. 최종 슬라이싱에서 `limit` 적용.

문제 2) 키워드 품질 저하
- 증상: 다단어 키워드/중복/일반어(“글”, “소개”)가 섞여 텍스트 리콜을 해치는 경우가 있었다.
- 해결: 공백 없는 단일 토큰, 1~5개, 불용어/특수문자 제거로 강제 정규화. 프롬프트에도 규칙을 명시해 모델 출력 자체를 개선.

문제 3) 재작성 노이즈
- 증상: 재작성의 질 편차가 커 의미적 노이즈로 작동하는 케이스가 있었다.
- 해결: 원 질문 대비 재작성 임베딩 코사인 유사도 기반으로 [0.6, 1.2] 가중치 부여, 유사도 0.35 미만 재작성은 벡터 경로에서 제외. 텍스트 경로에는 재작성 질의를 추가해 리콜은 유지.

문제 4) 융합 민감도와 확신 보너스
- 증상: 모달리티 간 점수 스케일 차이로 랭킹이 불안정하거나 “확신 높은 히트”가 충분히 부각되지 않는 문제.
- 해결: bias 프리셋에 기반한 임계치 부스팅(+0.1)을 도입해 높은 확신(정규화 점수 임계치 초과)에 일관된 보너스를 제공. 부작용을 막기 위해 1.0 캡과 로그(활성 카운트)를 추가해 튜닝 근거를 확보.

문제 5) 청크 Dedup 신뢰성
- 증상: 문자열 기반 청크 키로 Dedup 시 중복/충돌 위험.
- 해결: 스키마에 있는 `chunk_index`를 반환/활용해 Dedup 키를 `${postId}:${chunkIndex}`로 단순·안정화.

## 관측성과 운영

운영에서 누적 학습이 가능하도록 다음 로그를 표준화했다.
- `debug.plan.final`: 최종 정규화된 계획 요약(모드, top_k, limit, alpha, 시간 범위, 재작성/키워드 길이).
- `debug.hybrid.rewrite_weights`: 재작성 가중치와 keep/drop 여부.
- `debug.hybrid.boosts`: bias/alpha/임계치와 모달리티별 부스트 활성 카운트.

이를 통해 임계치가 너무 보수적/공격적인지, 재작성 품질이 충분한지, 모달리티 기여도가 균형적인지를 단계적으로 튜닝하고 있다.

## 트레이드오프와 향후 과제

- KNN 성격의 정확 계산은 결과 일관성과 필터 친화성을 얻는 대신, 전역 ANN 대비 일부 쿼리에서 지연이 늘 수 있다. `/ai/v2/ask`처럼 사용자/카테고리 pre-filter가 강한 경로에서는 KNN 접근이 비용 대비 안정적이었다. 반면 `/search/hybrid`처럼 글로벌 탐색에서는 ANN으로 전역 후보를 먼저 잡은 뒤 하이브리드 리랭크를 수행하는 것이 성능-품질 균형상 유리했다.
 - 향후 확장: 한 유저의 데이터가 대용량으로 성장하면, (a) 유저 단위 서브 인덱스(전용 HNSW)를 도입하거나, (b) 전역 ANN → user/category Post-filter의 두 단계 파이프라인으로 전환해 리콜·지연 균형을 재확보하는 방안을 고려한다. 이때 ANN 초기 후보 폭(top_k×factor)과 `ef_search` 튜닝이 관건이며, 필터 탈락률을 로그로 관측해 동적으로 factor를 조정하는 전략이 유효하다.
- min–max 정규화는 단순하고 직관적이나, 모달리티 내부 분산이 너무 작을 때 점수 붕괴 문제가 생길 수 있다. 이는 백로그로 남겨두었고, 필요 시 상수/epsilon 가드 또는 RRF/z-score 실험을 플래그로 도입할 계획이다.
- 태그 조인(post_tag/tag)은 데이터베이스 스키마 의존성이 있어 선택적으로 도입한다. 현재는 안정성과 이식성을 우선해 빈 배열로 폴백한다.

## 마무리

하이브리드 서치는 “벡터의 유연성”과 “텍스트의 정밀성”을 결합해 실제 사용자 질문에 강인한 검색 경험을 제공한다. 본 프로젝트에서는 pre-filter를 전제로 파이프라인을 재설계해 ANN 중심 구조보다 KNN 성격의 정확 계산을 택했고, 재작성/키워드 품질 관리, 임계치 부스팅, 다양성 보장 등 실전적 기법들로 안정성과 표현력을 확보했다. 남은 과제들은 로그와 지표를 기반으로 점진적으로 실험·도입할 예정이다.
